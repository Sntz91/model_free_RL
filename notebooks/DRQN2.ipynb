{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List, Union\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "Experience = namedtuple(\"Experience\",\n",
    "                           field_names = [\"observation\", \"action\", \"reward\"])\n",
    "\n",
    "class ReplayMemory:\n",
    "    \"\"\"\n",
    "    Replay Memory for Recurrent Neural Networks\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity: int, n_sequence_length: int):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        self.n_sequence_length = n_sequence_length\n",
    "  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    \n",
    "    def append(self, exp_sequence):\n",
    "        #if episode not long enough (n_sequence_length), then reject it\n",
    "        if(len(exp_sequence) > self.n_sequence_length):\n",
    "            self.buffer.append(exp_sequence)\n",
    "        \n",
    "        \n",
    "    def sample_episode(self):\n",
    "        idx = np.random.choice(len(self))\n",
    "        return self.buffer[idx]\n",
    "        \n",
    "        \n",
    "    def sample(self, batch_size: int = 1) -> Tuple:\n",
    "        #So a batch now contains batch_size *  sequences, right?\n",
    "        \n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            episode = self.sample_episode()\n",
    "\n",
    "            start_idx = np.random.choice(len(episode)-self.n_sequence_length)\n",
    "            trajectory = episode[start_idx : (start_idx + self.n_sequence_length)]\n",
    "            trajectories.append(trajectory)\n",
    "        \n",
    "        return trajectories\n",
    "\n",
    "    \n",
    "    \n",
    "rm = ReplayMemory(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start episode 1\n",
      "Start episode 2\n",
      "Start episode 3\n",
      "Start episode 4\n",
      "Start episode 5\n",
      "Start episode 6\n",
      "Start episode 7\n",
      "Start episode 8\n",
      "Start episode 9\n",
      "Start episode 10\n"
     ]
    }
   ],
   "source": [
    "episode = 0\n",
    "\n",
    "#Episode\n",
    "while(True):\n",
    "    episode+=1\n",
    "    print(\"Start episode %d\" % (episode))\n",
    "    done = False\n",
    "    episode_timestep = 0\n",
    "    \n",
    "    #Timestep\n",
    "    while(not done):\n",
    "        episode_timestep += 1\n",
    "        exp_sequence = []\n",
    "        \n",
    "        #simulate length of episode\n",
    "        n_timesteps = np.random.rand() * 100\n",
    "        n_timesteps = int(n_timesteps) + 1\n",
    "        \n",
    "        #simulate episode\n",
    "        for i in range(n_timesteps):\n",
    "            exp_sequence.append(Experience(i, i+2, i))\n",
    "            \n",
    "        done = True\n",
    "    rm.append(exp_sequence)\n",
    "         \n",
    "    if(episode>=10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Experience(observation=74, action=76, reward=74),\n",
       " Experience(observation=75, action=77, reward=75),\n",
       " Experience(observation=76, action=78, reward=76)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.sample(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(self, batch):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Experience(observation=27, action=29, reward=27),\n",
       "  Experience(observation=28, action=30, reward=28),\n",
       "  Experience(observation=29, action=31, reward=29)],\n",
       " [Experience(observation=32, action=34, reward=32),\n",
       "  Experience(observation=33, action=35, reward=33),\n",
       "  Experience(observation=34, action=36, reward=34)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = rm.sample(2)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first try to calc loss without batch, i.e. batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Experience(observation=20, action=22, reward=20),\n",
       " Experience(observation=21, action=23, reward=21),\n",
       " Experience(observation=22, action=24, reward=22)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory = rm.sample(1)[0]\n",
    "trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, actions, rewards = \\\n",
    "            zip(*[[t.observation, t.action, t.reward] for t in trajectory])\n",
    "obs = np.array(obs)\n",
    "actions = np.array(actions)\n",
    "rewards = np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 21, 22])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed obs into lstm, output for qval\n",
    "qvals = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRQN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class DRQN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network, choosing actions\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(DRQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(n_in[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(n_in)\n",
    "\n",
    "        self.lstm = nn.LSTM(conv_out_size, 512)\n",
    "        self.fc = nn.Linear(512, n_out)\n",
    "        \n",
    "        self.fc0 = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_out)\n",
    "        )\n",
    "        \n",
    "        self.hidden = np.repeat(0, 512)\n",
    "        #lstm needs hidden input\n",
    "        \n",
    "        \n",
    "        self.conv.apply(self.init_weights)\n",
    "        self.fc.apply(self.init_weights)\n",
    "\n",
    "        self.dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor #here\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.type(self.dtype) \n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc0(conv_out)\n",
    "        #lstm = self.lstm(conv_out, self.hidden)\n",
    "        #lstm_relu = nn.ReLU(lstm)\n",
    "        #return self.fc(lstm_relu)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "USE_PIL = True\n",
    "if USE_PIL:\n",
    "    # you should use pillow-simd, as it is faster than stardand Pillow\n",
    "    from PIL import Image\n",
    "else:\n",
    "    import cv2\n",
    "    cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Change image shape to CWH\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        new_shape = (old_shape[-1], old_shape[0], old_shape[1])\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0, high=1.0, shape=new_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.swapaxes(observation, 2, 0)\n",
    "    \n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=env.observation_space.shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # careful! This undoes the memory optimization, use\n",
    "        # with smaller replay buffers only.\n",
    "        return np.array(observation).astype(np.float32) / 255.0\n",
    "    \n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env, width=84, height=84, grayscale=True, dict_space_key=None):\n",
    "        \"\"\"\n",
    "        Warp frames to 84x84 as done in the Nature paper and later work.\n",
    "        If the environment uses dictionary observations, `dict_space_key` can be specified which indicates which\n",
    "        observation should be warped.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._grayscale = grayscale\n",
    "        self._key = dict_space_key\n",
    "        if self._grayscale:\n",
    "            num_colors = 1\n",
    "        else:\n",
    "            num_colors = 3\n",
    "\n",
    "        new_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(self._height, self._width, num_colors),\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "        if self._key is None:\n",
    "            original_space = self.observation_space\n",
    "            self.observation_space = new_space\n",
    "        else:\n",
    "            original_space = self.observation_space.spaces[self._key]\n",
    "            self.observation_space.spaces[self._key] = new_space\n",
    "        assert original_space.dtype == np.uint8 and len(original_space.shape) == 3\n",
    "\n",
    "    def observation(self, obs):\n",
    "        if self._key is None:\n",
    "            frame = obs\n",
    "        else:\n",
    "            frame = obs[self._key]\n",
    "        if USE_PIL:\n",
    "            frame = Image.fromarray(frame)\n",
    "            if self._grayscale:\n",
    "                frame = frame.convert(\"L\")\n",
    "            frame = frame.resize((self._width, self._height))\n",
    "            frame = np.array(frame)\n",
    "        else:\n",
    "            if self._grayscale:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            frame = cv2.resize(\n",
    "                frame, (self._width, self._height),\n",
    "                interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "        if self._grayscale:\n",
    "            frame = np.expand_dims(frame, -1)\n",
    "\n",
    "        if self._key is None:\n",
    "            obs = frame\n",
    "        else:\n",
    "            obs = obs.copy()\n",
    "            obs[self._key] = frame\n",
    "        return obs\n",
    "\n",
    "env_name = 'SeaquestNoFrameskip-v4'\n",
    "env = gym.make(env_name)\n",
    "env = WarpFrame(env)\n",
    "env = ImageToPyTorch(env)\n",
    "#env = ScaledFloatFrame(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "obs = env.reset()\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obs = torch.tensor(obs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add batch dimension \n",
    "obs = obs.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 84, 84])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DRQN(env.observation_space.shape, env.action_space.n).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8340,  2.4123,  0.4724,  0.2797,  0.1478, -0.3460, -0.6617,  1.1070,\n",
       "          2.0227,  0.7061, -0.6693, -0.4380, -1.0374, -0.5745, -0.7978,  1.4820,\n",
       "          0.2428, -1.0787]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obviously i need the hidden states!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i need one hidden input for each LSTM, if there are 3 LSTM, then 3 obv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
